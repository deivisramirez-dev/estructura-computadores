<!DOCTYPE html>
<html lang="es" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lienzo Did√°ctico - Computadores Paralelos</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header class="header">
            <div class="header-content">
                <h1 class="main-title">
                    <i class="fas fa-sitemap"></i>
                    Tema 9: Introducci√≥n a los Computadores Paralelos
                </h1>
                <p class="subtitle">Arquitecturas MIMD y sistemas con m√∫ltiples procesadores</p>
            </div>
        </header>

        <!-- Navigation -->
        <nav class="nav">
            <div class="nav-content">
                <div class="nav-info">
                    <i class="fas fa-graduation-cap"></i>
                    <span>Programa de Ingenier√≠a Inform√°tica</span>
                </div>
                <div class="nav-controls">
                    <button class="btn btn-back" onclick="goToMainPortal()">
                        <i class="fas fa-home"></i>
                        <span>Portal Principal</span>
                    </button>
                    <button class="btn btn-secondary" onclick="toggleTheme()">
                        <i class="fas fa-moon"></i>
                        <span>Tema Oscuro</span>
                    </button>
                    <button class="btn btn-primary" onclick="toggleFullscreen()">
                        <i class="fas fa-expand"></i>
                        <span>Pantalla Completa</span>
                    </button>
                </div>
            </div>
        </nav>

        <!-- Main Content -->
        <main class="main">
            <!-- Navigation para secciones del tema -->
            <nav class="navigation">
                <div class="nav-buttons">
                    <button class="nav-btn active" data-section="introduccion">
                        <i class="fas fa-info-circle"></i>
                        <span>Introducci√≥n</span>
                    </button>
                    <button class="nav-btn" data-section="paralelismo">
                        <i class="fas fa-layer-group"></i>
                        <span>Niveles de Paralelismo</span>
                    </button>
                    <button class="nav-btn" data-section="clasificacion">
                        <i class="fas fa-project-diagram"></i>
                        <span>Clasificaci√≥n MIMD</span>
                    </button>
                    <button class="nav-btn" data-section="multiprocesadores">
                        <i class="fas fa-microchip"></i>
                        <span>Multiprocesadores</span>
                    </button>
                    <button class="nav-btn" data-section="multicomputadores">
                        <i class="fas fa-server"></i>
                        <span>Multicomputadores</span>
                    </button>
                    <button class="nav-btn" data-section="prestaciones">
                        <i class="fas fa-chart-line"></i>
                        <span>Prestaciones</span>
                    </button>
                    <button class="nav-btn" data-section="programacion">
                        <i class="fas fa-code"></i>
                        <span>Programaci√≥n Paralela</span>
                    </button>
                    <button class="nav-btn" data-section="optimizacion">
                        <i class="fas fa-tachometer-alt"></i>
                        <span>Optimizaci√≥n</span>
                    </button>
                    <button class="nav-btn" data-section="ejemplos">
                        <i class="fas fa-flask"></i>
                        <span>Ejemplos Pr√°cticos</span>
                    </button>
                </div>
            </nav>

            <!-- Introducci√≥n Section -->
            <section id="introduccion" class="content-section active">
                <div class="section-header">
                    <h2><i class="fas fa-info-circle"></i> Introducci√≥n a los Computadores Paralelos</h2>
                    <p>Arquitecturas MIMD y sistemas con m√∫ltiples procesadores</p>
                </div>
                
                <div class="content-grid">
                    <div class="card definition-card">
                        <h3><i class="fas fa-quote-left"></i> Definici√≥n</h3>
                        <p class="highlight">"Los computadores paralelos son arquitecturas paralelas, a nivel de sistema computador, implementadas replicando procesadores."</p>
                        <div class="definition-details">
                            <div class="detail-item">
                                <i class="fas fa-sitemap"></i>
                                <span>Clasificaci√≥n MIMD de Flynn</span>
                            </div>
                            <div class="detail-item">
                                <i class="fas fa-microchip"></i>
                                <span>M√∫ltiples procesadores</span>
                            </div>
                            <div class="detail-item">
                                <i class="fas fa-cogs"></i>
                                <span>Procesamiento simult√°neo</span>
                            </div>
                        </div>
                    </div>

                    <div class="card motivation-card">
                        <h3><i class="fas fa-lightbulb"></i> Motivaci√≥n</h3>
                        <div class="motivation-list">
                            <div class="motivation-item">
                                <i class="fas fa-check-circle"></i>
                                <div>
                                    <strong>Aplicaciones que requieren arquitecturas paralelas:</strong> Simulaciones cient√≠ficas, procesamiento de datos masivos
                                </div>
                            </div>
                            <div class="motivation-item">
                                <i class="fas fa-check-circle"></i>
                                <div>
                                    <strong>Accesibilidad del hardware:</strong> Componentes comerciales disponibles
                                </div>
                            </div>
                            <div class="motivation-item">
                                <i class="fas fa-check-circle"></i>
                                <div>
                                    <strong>Optimizaci√≥n de prestaciones:</strong> Mejora de la relaci√≥n rendimiento/coste
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card alternatives-card">
                        <h3><i class="fas fa-cogs"></i> Alternativas para Implementar Paralelismo</h3>
                        <div class="alternatives-grid">
                            <div class="alternative-item">
                                <h4><i class="fas fa-stream"></i> Segmentaci√≥n</h4>
                                <p>Divisi√≥n del sistema en etapas conectadas en cascada (pipeline)</p>
                                <ul>
                                    <li>Cauce segmentado</li>
                                    <li>Pipeline de instrucciones</li>
                                    <li>Procesamiento en etapas</li>
                                </ul>
                            </div>
                            <div class="alternative-item">
                                <h4><i class="fas fa-copy"></i> Replicaci√≥n de Componentes</h4>
                                <p>Unidades funcionales iguales con conexi√≥n paralela</p>
                                <ul>
                                    <li>M√∫ltiples ALUs</li>
                                    <li>Procesadores independientes</li>
                                    <li>Unidades especializadas</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="card flynn-card">
                        <h3><i class="fas fa-project-diagram"></i> Clasificaci√≥n Flynn</h3>
                        <div class="flynn-classification">
                            <div class="flynn-item">
                                <h4>SISD</h4>
                                <p>Single Instruction, Single Data</p>
                                <p>Procesador tradicional secuencial</p>
                            </div>
                            <div class="flynn-item">
                                <h4>SIMD</h4>
                                <p>Single Instruction, Multiple Data</p>
                                <p>Procesamiento vectorial</p>
                            </div>
                            <div class="flynn-item">
                                <h4>MISD</h4>
                                <p>Multiple Instruction, Single Data</p>
                                <p>M√∫ltiples procesadores sobre mismos datos</p>
                            </div>
                            <div class="flynn-item">
                                <h4>MIMD</h4>
                                <p>Multiple Instruction, Multiple Data</p>
                                <p><strong>Computadores paralelos</strong></p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Paralelismo Section -->
            <section id="paralelismo" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-layer-group"></i> Niveles de Paralelismo</h2>
                    <p>Clasificaci√≥n del paralelismo seg√∫n el nivel de abstracci√≥n</p>
                </div>
                
                <div class="content-grid">
                    <div class="card levels-card">
                        <h3><i class="fas fa-sitemap"></i> Niveles de Paralelismo Funcional</h3>
                        <div class="parallelism-levels">
                            <div class="level-item">
                                <h4>Nivel de Programa</h4>
                                <p>Paralelismo entre programas independientes</p>
                                <div class="level-example">
                                    <code>Programa A || Programa B || Programa C</code>
                                </div>
                            </div>
                            <div class="level-item">
                                <h4>Nivel de Funciones</h4>
                                <p>Paralelismo entre funciones dentro de un programa</p>
                                <div class="level-example">
                                    <code>func1() || func2() || func3()</code>
                                </div>
                            </div>
                            <div class="level-item">
                                <h4>Nivel de Bucles</h4>
                                <p>Paralelismo en iteraciones de bucles</p>
                                <div class="level-example">
                                    <code>for i in parallel: process(data[i])</code>
                                </div>
                            </div>
                            <div class="level-item">
                                <h4>Nivel de Operaciones</h4>
                                <p>Paralelismo a nivel de instrucciones</p>
                                <div class="level-example">
                                    <code>ADD || MUL || LOAD</code>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card granularity-card">
                        <h3><i class="fas fa-balance-scale"></i> Granularidad del Paralelismo</h3>
                        <div class="granularity-chart">
                            <div class="granularity-item fine">
                                <h4>Granularidad Fina</h4>
                                <p>Pocas operaciones por unidad paralela</p>
                                <div class="granularity-bar">
                                    <div class="bar-fill" style="width: 20%"></div>
                                </div>
                                <p>Ejemplo: Instrucciones individuales</p>
                            </div>
                            <div class="granularity-item medium">
                                <h4>Granularidad Media</h4>
                                <p>N√∫mero moderado de operaciones</p>
                                <div class="granularity-bar">
                                    <div class="bar-fill" style="width: 50%"></div>
                                </div>
                                <p>Ejemplo: Bucles, funciones</p>
                            </div>
                            <div class="granularity-item coarse">
                                <h4>Granularidad Gruesa</h4>
                                <p>Muchas operaciones por unidad paralela</p>
                                <div class="granularity-bar">
                                    <div class="bar-fill" style="width: 80%"></div>
                                </div>
                                <p>Ejemplo: Programas completos</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card types-card">
                        <h3><i class="fas fa-code"></i> Tipos de Paralelismo de Aplicaci√≥n</h3>
                        <div class="parallelism-types">
                            <div class="type-item">
                                <h4><i class="fas fa-tasks"></i> Paralelismo de Tareas</h4>
                                <p>Extracci√≥n de la estructura l√≥gica de funciones</p>
                                <div class="type-example">
                                    <h5>Ejemplo:</h5>
                                    <code>
                                        Task1: Leer datos<br>
                                        Task2: Procesar datos<br>
                                        Task3: Escribir resultados
                                    </code>
                                </div>
                            </div>
                            <div class="type-item">
                                <h4><i class="fas fa-database"></i> Paralelismo de Datos</h4>
                                <p>Operaciones sobre estructuras de datos (matrices)</p>
                                <div class="type-example">
                                    <h5>Ejemplo:</h5>
                                    <code>
                                        for i in parallel:<br>
                                        &nbsp;&nbsp;result[i] = matrix[i] * vector[i]
                                    </code>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card units-card">
                        <h3><i class="fas fa-microchip"></i> Unidades de Ejecuci√≥n</h3>
                        <div class="execution-units">
                            <div class="unit-item">
                                <h4><i class="fas fa-cog"></i> Hardware (Procesador)</h4>
                                <p>Gestiona la ejecuci√≥n de instrucciones</p>
                                <ul>
                                    <li>Procesamiento de instrucciones</li>
                                    <li>Control de flujo</li>
                                    <li>Acceso a memoria</li>
                                </ul>
                            </div>
                            <div class="unit-item">
                                <h4><i class="fas fa-desktop"></i> Software (Sistema Operativo)</h4>
                                <p>Gestiona procesos y hebras</p>
                                <ul>
                                    <li>Procesos independientes</li>
                                    <li>Hilos (threads)</li>
                                    <li>Planificaci√≥n de tareas</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Clasificaci√≥n Section -->
            <section id="clasificacion" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-project-diagram"></i> Clasificaci√≥n de Computadores Paralelos</h2>
                    <p>Organizaci√≥n seg√∫n el sistema de memoria</p>
                </div>
                
                <div class="content-grid">
                    <div class="card classification-card">
                        <h3><i class="fas fa-sitemap"></i> Clasificaci√≥n Principal</h3>
                        <div class="classification-tree">
                            <div class="tree-node root">
                                <h4>Computadores Paralelos MIMD</h4>
                            </div>
                            <div class="tree-branch">
                                <div class="tree-node">
                                    <h4>Multiprocesadores</h4>
                                    <p>Memoria Compartida (SM)</p>
                                </div>
                                <div class="tree-children">
                                    <div class="tree-node">
                                        <h5>UMA</h5>
                                        <p>Acceso Uniforme a Memoria</p>
                                    </div>
                                    <div class="tree-node">
                                        <h5>NUMA</h5>
                                        <p>Acceso No Uniforme a Memoria</p>
                                    </div>
                                </div>
                            </div>
                            <div class="tree-branch">
                                <div class="tree-node">
                                    <h4>Multicomputadores</h4>
                                    <p>Memoria Distribuida (DM)</p>
                                </div>
                                <div class="tree-children">
                                    <div class="tree-node">
                                        <h5>MPP</h5>
                                        <p>Procesadores Masivamente Paralelos</p>
                                    </div>
                                    <div class="tree-node">
                                        <h5>Cl√∫ster</h5>
                                        <p>Agrupaci√≥n de computadores</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card comparison-card">
                        <h3><i class="fas fa-balance-scale"></i> Comparaci√≥n Multiprocesadores vs Multicomputadores</h3>
                        <div class="comparison-table">
                            <div class="comparison-header">
                                <div class="comparison-cell">Caracter√≠stica</div>
                                <div class="comparison-cell">Multiprocesadores</div>
                                <div class="comparison-cell">Multicomputadores</div>
                            </div>
                            <div class="comparison-row">
                                <div class="comparison-cell"><strong>Memoria</strong></div>
                                <div class="comparison-cell">Compartida</div>
                                <div class="comparison-cell">Distribuida</div>
                            </div>
                            <div class="comparison-row">
                                <div class="comparison-cell"><strong>Comunicaci√≥n</strong></div>
                                <div class="comparison-cell">Variables compartidas</div>
                                <div class="comparison-cell">Paso de mensajes</div>
                            </div>
                            <div class="comparison-row">
                                <div class="comparison-cell"><strong>Escalabilidad</strong></div>
                                <div class="comparison-cell">Limitada</div>
                                <div class="comparison-cell">Alta</div>
                            </div>
                            <div class="comparison-row">
                                <div class="comparison-cell"><strong>Programaci√≥n</strong></div>
                                <div class="comparison-cell">M√°s sencilla</div>
                                <div class="comparison-cell">M√°s compleja</div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Multiprocesadores Section -->
            <section id="multiprocesadores" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-microchip"></i> Multiprocesadores (Memoria Compartida)</h2>
                    <p>Sistemas con memoria compartida y espacio de direccionamiento √∫nico</p>
                </div>
                
                <div class="content-grid">
                    <div class="card smp-card">
                        <h3><i class="fas fa-sitemap"></i> SMP (Symmetric MultiProcessor)</h3>
                        <div class="smp-diagram">
                            <div class="processor-grid">
                                <div class="processor">CPU 1</div>
                                <div class="processor">CPU 2</div>
                                <div class="processor">CPU 3</div>
                                <div class="processor">CPU 4</div>
                            </div>
                            <div class="memory-shared">
                                <h4>Memoria Compartida</h4>
                                <p>Acceso uniforme para todos los procesadores</p>
                            </div>
                        </div>
                        <div class="smp-characteristics">
                            <h4>Caracter√≠sticas:</h4>
                            <ul>
                                <li>Acceso uniforme a memoria (UMA)</li>
                                <li>Comunicaci√≥n mediante variables compartidas</li>
                                <li>Programaci√≥n m√°s sencilla</li>
                                <li>Escalabilidad limitada</li>
                            </ul>
                        </div>
                    </div>

                    <div class="card numa-card">
                        <h3><i class="fas fa-network-wired"></i> NUMA (Non-Uniform Memory Access)</h3>
                        <div class="numa-diagram">
                            <div class="numa-node">
                                <div class="processor">CPU 1</div>
                                <div class="memory-local">Memoria Local</div>
                            </div>
                            <div class="numa-node">
                                <div class="processor">CPU 2</div>
                                <div class="memory-local">Memoria Local</div>
                            </div>
                            <div class="interconnect">Red de Interconexi√≥n</div>
                        </div>
                        <div class="numa-characteristics">
                            <h4>Caracter√≠sticas:</h4>
                            <ul>
                                <li>Acceso no uniforme a memoria</li>
                                <li>Memoria distribuida f√≠sicamente</li>
                                <li>Mayor escalabilidad</li>
                                <li>Latencia variable seg√∫n ubicaci√≥n</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card coherence-card">
                        <h3><i class="fas fa-sync"></i> Coherencia de Cach√©</h3>
                        <div class="coherence-explanation">
                            <p>En sistemas con memoria compartida, m√∫ltiples procesadores pueden tener copias de los mismos datos en sus cach√©s. La coherencia de cach√© garantiza que todas las copias sean consistentes.</p>
                            
                            <div class="coherence-protocols">
                                <h4>Protocolos de Coherencia:</h4>
                                <div class="protocol-item">
                                    <h5>MSI (Modified, Shared, Invalid)</h5>
                                    <p>Estados: Modificado, Compartido, Inv√°lido</p>
                                </div>
                                <div class="protocol-item">
                                    <h5>MESI (Modified, Exclusive, Shared, Invalid)</h5>
                                    <p>Estados: Modificado, Exclusivo, Compartido, Inv√°lido</p>
                                </div>
                                <div class="protocol-item">
                                    <h5>MOESI (Modified, Owned, Exclusive, Shared, Invalid)</h5>
                                    <p>Estados: Modificado, Propio, Exclusivo, Compartido, Inv√°lido</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card synchronization-card">
                        <h3><i class="fas fa-lock"></i> Sincronizaci√≥n</h3>
                        <div class="synchronization-methods">
                            <h4>M√©todos de Sincronizaci√≥n:</h4>
                            <div class="sync-item">
                                <h5><i class="fas fa-flag"></i> Sem√°foros</h5>
                                <p>Control de acceso a recursos compartidos</p>
                            </div>
                            <div class="sync-item">
                                <h5><i class="fas fa-lock"></i> Mutex</h5>
                                <p>Exclusi√≥n mutua para secciones cr√≠ticas</p>
                            </div>
                            <div class="sync-item">
                                <h5><i class="fas fa-bars"></i> Barreras</h5>
                                <p>Sincronizaci√≥n de puntos de ejecuci√≥n</p>
                            </div>
                            <div class="sync-item">
                                <h5><i class="fas fa-exchange-alt"></i> Variables de Condici√≥n</h5>
                                <p>Espera de condiciones espec√≠ficas</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Multicomputadores Section -->
            <section id="multicomputadores" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-server"></i> Multicomputadores (Memoria Distribuida)</h2>
                    <p>Sistemas con memoria distribuida y comunicaci√≥n por mensajes</p>
                </div>
                
                <div class="content-grid">
                    <div class="card dm-card">
                        <h3><i class="fas fa-sitemap"></i> Caracter√≠sticas de Memoria Distribuida</h3>
                        <div class="dm-diagram">
                            <div class="dm-node">
                                <div class="processor">CPU 1</div>
                                <div class="memory-private">Memoria Privada</div>
                                <div class="network-interface">NI</div>
                            </div>
                            <div class="dm-node">
                                <div class="processor">CPU 2</div>
                                <div class="memory-private">Memoria Privada</div>
                                <div class="network-interface">NI</div>
                            </div>
                            <div class="network">Red de Interconexi√≥n</div>
                        </div>
                        <div class="dm-characteristics">
                            <h4>Caracter√≠sticas:</h4>
                            <ul>
                                <li>Cada procesador tiene su espacio de direccionamiento</li>
                                <li>Comunicaci√≥n mediante paso de mensajes</li>
                                <li>Alta escalabilidad</li>
                                <li>Programaci√≥n m√°s compleja</li>
                            </ul>
                        </div>
                    </div>

                    <div class="card message-passing-card">
                        <h3><i class="fas fa-comments"></i> Comunicaci√≥n por Mensajes</h3>
                        <div class="message-passing">
                            <div class="message-example">
                                <h4>Operaciones B√°sicas:</h4>
                                <div class="code-example">
                                    <code>
                                        // Proceso A (Enviador)<br>
                                        send(data, destination);<br><br>
                                        // Proceso B (Receptor)<br>
                                        receive(data, source);
                                    </code>
                                </div>
                            </div>
                            <div class="message-types">
                                <h4>Tipos de Comunicaci√≥n:</h4>
                                <div class="type-item">
                                    <h5>S√≠ncrona</h5>
                                    <p>El env√≠o espera confirmaci√≥n de recepci√≥n</p>
                                </div>
                                <div class="type-item">
                                    <h5>As√≠ncrona</h5>
                                    <p>El env√≠o no espera confirmaci√≥n</p>
                                </div>
                                <div class="type-item">
                                    <h5>Bloqueante</h5>
                                    <p>La operaci√≥n bloquea hasta completarse</p>
                                </div>
                                <div class="type-item">
                                    <h5>No Bloqueante</h5>
                                    <p>La operaci√≥n retorna inmediatamente</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card cluster-card">
                        <h3><i class="fas fa-server"></i> Cl√∫steres y Configuraciones</h3>
                        <div class="cluster-types">
                            <div class="cluster-item">
                                <h4><i class="fas fa-server"></i> Cl√∫ster Beowulf</h4>
                                <p>Agrupaci√≥n de computadores comerciales con Linux</p>
                                <ul>
                                    <li>Coste reducido</li>
                                    <li>F√°cil mantenimiento</li>
                                    <li>Escalabilidad horizontal</li>
                                </ul>
                            </div>
                            <div class="cluster-item">
                                <h4><i class="fas fa-network-wired"></i> NOW (Network of Workstations)</h4>
                                <p>Red de estaciones de trabajo interconectadas</p>
                                <ul>
                                    <li>Aprovecha recursos ociosos</li>
                                    <li>Coste m√≠nimo</li>
                                    <li>Rendimiento variable</li>
                                </ul>
                            </div>
                            <div class="cluster-item">
                                <h4><i class="fas fa-globe"></i> Grid Computing</h4>
                                <p>Computaci√≥n distribuida a gran escala</p>
                                <ul>
                                    <li>Recursos geogr√°ficamente distribuidos</li>
                                    <li>Est√°ndares abiertos</li>
                                    <li>Computaci√≥n voluntaria</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="card mpp-card">
                        <h3><i class="fas fa-microchip"></i> MPP (Massively Parallel Processors)</h3>
                        <div class="mpp-characteristics">
                            <h4>Caracter√≠sticas de MPP:</h4>
                            <ul>
                                <li>Miles de procesadores</li>
                                <li>Memoria distribuida</li>
                                <li>Red de interconexi√≥n de alta velocidad</li>
                                <li>Optimizado para aplicaciones cient√≠ficas</li>
                            </ul>
                            
                            <div class="mpp-examples">
                                <h4>Ejemplos Hist√≥ricos:</h4>
                                <div class="example-item">
                                    <strong>IBM Blue Gene:</strong> Hasta 1M procesadores
                                </div>
                                <div class="example-item">
                                    <strong>Cray T3E:</strong> Hasta 2048 procesadores
                                </div>
                                <div class="example-item">
                                    <strong>Intel Paragon:</strong> Hasta 4096 procesadores
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Prestaciones Section -->
            <section id="prestaciones" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-chart-line"></i> Prestaciones en Computadores Paralelos</h2>
                    <p>M√©tricas y medidas de rendimiento</p>
                </div>
                
                <div class="content-grid">
                    <div class="card metrics-card">
                        <h3><i class="fas fa-tachometer-alt"></i> M√©tricas de Prestaciones</h3>
                        <div class="performance-metrics">
                            <div class="metric-item">
                                <h4><i class="fas fa-clock"></i> Tiempo de Ejecuci√≥n</h4>
                                <p>Tiempo necesario para ejecutar una aplicaci√≥n</p>
                                <div class="metric-formula">
                                    <code>T(p) = T_c(p) + T_o(p)</code>
                                    <p>Donde T_c es tiempo de c√≥mputo y T_o es sobrecarga</p>
                                </div>
                            </div>
                            <div class="metric-item">
                                <h4><i class="fas fa-tachometer-alt"></i> Throughput</h4>
                                <p>N√∫mero de aplicaciones procesadas por unidad de tiempo</p>
                                <div class="metric-formula">
                                    <code>Throughput = Aplicaciones / Tiempo</code>
                                </div>
                            </div>
                            <div class="metric-item">
                                <h4><i class="fas fa-chart-line"></i> Speedup</h4>
                                <p>Mejora en el rendimiento con m√∫ltiples procesadores</p>
                                <div class="metric-formula">
                                    <code>S(p) = T(1) / T(p)</code>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card speedup-card">
                        <h3><i class="fas fa-chart-line"></i> Tipos de Speedup</h3>
                        <div class="speedup-types">
                            <div class="speedup-item">
                                <h4>Lineal: S(p) = p</h4>
                                <p>Distribuci√≥n perfecta del trabajo</p>
                                <div class="speedup-bar">
                                    <div class="bar-fill linear" style="width: 100%"></div>
                                </div>
                            </div>
                            <div class="speedup-item">
                                <h4>Superlineal: S(p) > p</h4>
                                <p>Beneficios adicionales del paralelismo</p>
                                <div class="speedup-bar">
                                    <div class="bar-fill superlinear" style="width: 120%"></div>
                                </div>
                            </div>
                            <div class="speedup-item">
                                <h4>Sublineal: S(p) < p</h4>
                                <p>Limitaciones del paralelismo</p>
                                <div class="speedup-bar">
                                    <div class="bar-fill sublinear" style="width: 60%"></div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card amdahl-card">
                        <h3><i class="fas fa-calculator"></i> Ley de Amdahl</h3>
                        <div class="amdahl-formula">
                            <h4>F√≥rmula de Amdahl:</h4>
                            <div class="formula">
                                <code>S(p) = 1 / ((1 - f) + f/p)</code>
                            </div>
                            <div class="formula-explanation">
                                <p><strong>f:</strong> Fracci√≥n paralelizable del programa</p>
                                <p><strong>p:</strong> N√∫mero de procesadores</p>
                                <p><strong>S(p):</strong> Speedup obtenido</p>
                            </div>
                        </div>
                        <div class="amdahl-calculator">
                            <h4>Calculadora de Speedup:</h4>
                            <div class="input-group">
                                <label for="parallel-fraction">Fracci√≥n Paralelizable (f):</label>
                                <input type="range" id="parallel-fraction" min="0" max="1" step="0.01" value="0.8">
                                <span id="parallel-fraction-value">0.8</span>
                            </div>
                            <div class="input-group">
                                <label for="processors">N√∫mero de Procesadores (p):</label>
                                <input type="range" id="processors" min="1" max="64" value="4">
                                <span id="processors-value">4</span>
                            </div>
                            <div class="result">
                                <strong>Speedup: <span id="speedup-result">2.5</span>x</strong>
                            </div>
                        </div>
                    </div>

                    <div class="card efficiency-card">
                        <h3><i class="fas fa-chart-pie"></i> Eficiencia del Sistema</h3>
                        <div class="efficiency-metrics">
                            <div class="efficiency-item">
                                <h4>Eficiencia</h4>
                                <div class="formula">
                                    <code>E(p) = S(p) / p</code>
                                </div>
                                <p>Relaci√≥n entre speedup y n√∫mero de procesadores</p>
                            </div>
                            <div class="efficiency-item">
                                <h4>Isoeficiencia</h4>
                                <p>Funci√≥n que indica c√≥mo debe crecer el tama√±o del problema para mantener la eficiencia constante</p>
                            </div>
                            <div class="efficiency-item">
                                <h4>Escalabilidad</h4>
                                <p>Capacidad del sistema para mantener o mejorar el rendimiento al aumentar el n√∫mero de procesadores</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Programaci√≥n Paralela Section -->
            <section id="programacion" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-code"></i> Programaci√≥n Paralela Pr√°ctica</h2>
                    <p>Herramientas y t√©cnicas para desarrollar aplicaciones paralelas</p>
                </div>
                
                <div class="content-grid">
                    <div class="card openmp-card">
                        <h3><i class="fas fa-microchip"></i> OpenMP (Memoria Compartida)</h3>
                        <div class="openmp-content">
                            <div class="openmp-intro">
                                <h4>¬øQu√© es OpenMP?</h4>
                                <p><strong>OpenMP (Open Multi-Processing)</strong> es un est√°ndar de programaci√≥n paralela para sistemas de <strong>memoria compartida</strong>. Permite paralelizar programas de forma relativamente sencilla usando directivas del compilador.</p>
                                
                                <div class="concept-explanation">
                                    <h5>üîß Caracter√≠sticas Principales:</h5>
                                    <ul>
                                        <li><strong>Directivas del compilador:</strong> Instrucciones especiales que le dicen al compilador c√≥mo paralelizar el c√≥digo</li>
                                        <li><strong>Paralelizaci√≥n autom√°tica:</strong> El compilador se encarga de crear y gestionar los hilos</li>
                                        <li><strong>Memoria compartida:</strong> Todos los hilos pueden acceder a la misma memoria</li>
                                        <li><strong>F√°cil de usar:</strong> Solo necesitas agregar directivas a tu c√≥digo existente</li>
                                    </ul>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h5>üèóÔ∏è Arquitectura:</h5>
                                    <p>OpenMP funciona en sistemas donde m√∫ltiples procesadores comparten la misma memoria RAM. Es ideal para:</p>
                                    <ul>
                                        <li>Servidores con m√∫ltiples n√∫cleos</li>
                                        <li>Estaciones de trabajo de alto rendimiento</li>
                                        <li>Supercomputadores con memoria compartida</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="openmp-features">
                                <h4>Directivas Principales:</h4>
                                <ul>
                                    <li><strong>#pragma omp parallel:</strong> Crea un equipo de hilos</li>
                                    <li><strong>#pragma omp parallel for:</strong> Paraleliza un bucle</li>
                                    <li><strong>#pragma omp critical:</strong> Secci√≥n cr√≠tica (solo un hilo a la vez)</li>
                                    <li><strong>#pragma omp reduction:</strong> Operaciones de reducci√≥n (suma, producto, etc.)</li>
                                </ul>
                            </div>
                            <div class="code-example">
                                <h4>Ejemplo 1: Suma de Elementos de un Vector</h4>
                                <div class="example-context">
                                    <h5>üìã Enunciado:</h5>
                                    <p>Dado un vector de N elementos, calcular la suma de todos sus elementos utilizando OpenMP. El programa debe mostrar el tiempo de ejecuci√≥n y el resultado final.</p>
                                </div>
                                <div class="code-block">
                                    <code>
                                        #include &lt;omp.h&gt;<br>
                                        #include &lt;stdio.h&gt;<br>
                                        #include &lt;stdlib.h&gt;<br>
                                        #include &lt;time.h&gt;<br><br>
                                        #define N 1000000<br><br>
                                        int main() {<br>
                                        &nbsp;&nbsp;int *vector = (int*)malloc(N * sizeof(int));<br>
                                        &nbsp;&nbsp;long long suma = 0;<br>
                                        &nbsp;&nbsp;double start_time, end_time;<br><br>
                                        &nbsp;&nbsp;// Inicializar vector con valores aleatorios<br>
                                        &nbsp;&nbsp;for(int i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;vector[i] = rand() % 100;<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;start_time = omp_get_wtime();<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;// Paralelizaci√≥n con OpenMP<br>
                                        &nbsp;&nbsp;#pragma omp parallel for reduction(+:suma)<br>
                                        &nbsp;&nbsp;for(int i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;suma += vector[i];<br>
                                        &nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;end_time = omp_get_wtime();<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;printf("Suma total: %lld\n", suma);<br>
                                        &nbsp;&nbsp;printf("Tiempo de ejecuci√≥n: %f segundos\n", end_time - start_time);<br>
                                        &nbsp;&nbsp;printf("Hilos utilizados: %d\n", omp_get_max_threads());<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;free(vector);<br>
                                        &nbsp;&nbsp;return 0;<br>
                                        }
                                    </code>
                                </div>
                                <div class="explanation">
                                    <h5>üîç Explicaci√≥n Detallada:</h5>
                                    <ul>
                                        <li><strong>#pragma omp parallel for:</strong> Crea m√∫ltiples hilos y distribuye las iteraciones del bucle entre ellos</li>
                                        <li><strong>reduction(+:suma):</strong> Cada hilo mantiene una copia local de 'suma', al final se suman todas las copias</li>
                                        <li><strong>omp_get_wtime():</strong> Funci√≥n de OpenMP para medir tiempo de ejecuci√≥n con alta precisi√≥n</li>
                                        <li><strong>omp_get_max_threads():</strong> Obtiene el n√∫mero m√°ximo de hilos disponibles</li>
                                        <li><strong>Ventaja:</strong> El bucle se ejecuta en paralelo, reduciendo significativamente el tiempo de ejecuci√≥n</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="code-example">
                                <h4>Ejemplo 2: Multiplicaci√≥n de Matrices</h4>
                                <div class="example-context">
                                    <h5>üìã Enunciado:</h5>
                                    <p>Implementar la multiplicaci√≥n de dos matrices cuadradas de NxN utilizando OpenMP. Comparar el rendimiento con diferentes n√∫meros de hilos.</p>
                                </div>
                                <div class="code-block">
                                    <code>
                                        #include &lt;omp.h&gt;<br>
                                        #include &lt;stdio.h&gt;<br>
                                        #include &lt;stdlib.h&gt;<br><br>
                                        #define N 512<br><br>
                                        void matrix_multiply(double **A, double **B, double **C) {<br>
                                        &nbsp;&nbsp;#pragma omp parallel for<br>
                                        &nbsp;&nbsp;for(int i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(int j = 0; j &lt; N; j++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C[i][j] = 0.0;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for(int k = 0; k &lt; N; k++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C[i][j] += A[i][k] * B[k][j];<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;}<br>
                                        }<br><br>
                                        int main() {<br>
                                        &nbsp;&nbsp;// Asignar memoria para matrices<br>
                                        &nbsp;&nbsp;double **A = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;double **B = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;double **C = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;for(int i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;A[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;B[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;C[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;// Inicializar matrices<br>
                                        &nbsp;&nbsp;for(int i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(int j = 0; j &lt; N; j++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A[i][j] = 1.0;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B[i][j] = 1.0;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;double start = omp_get_wtime();<br>
                                        &nbsp;&nbsp;matrix_multiply(A, B, C);<br>
                                        &nbsp;&nbsp;double end = omp_get_wtime();<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;printf("Tiempo de ejecuci√≥n: %f segundos\n", end - start);<br>
                                        &nbsp;&nbsp;printf("Hilos utilizados: %d\n", omp_get_num_threads());<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;// Liberar memoria<br>
                                        &nbsp;&nbsp;for(int i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;free(A[i]); free(B[i]); free(C[i]);<br>
                                        &nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;free(A); free(B); free(C);<br>
                                        &nbsp;&nbsp;return 0;<br>
                                        }
                                    </code>
                                </div>
                                <div class="explanation">
                                    <h5>üîç Explicaci√≥n Detallada:</h5>
                                    <ul>
                                        <li><strong>Paralelizaci√≥n del bucle externo:</strong> Solo el bucle 'i' se paraleliza para evitar condiciones de carrera</li>
                                        <li><strong>Independencia de datos:</strong> Cada hilo calcula filas diferentes de la matriz resultado</li>
                                        <li><strong>Acceso a memoria:</strong> Cada hilo accede a diferentes filas, minimizando conflictos de cach√©</li>
                                        <li><strong>Escalabilidad:</strong> El rendimiento mejora proporcionalmente al n√∫mero de hilos (hasta cierto punto)</li>
                                        <li><strong>Complejidad:</strong> O(N¬≥) con paralelizaci√≥n O(N¬≤) en el bucle externo</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card mpi-card">
                        <h3><i class="fas fa-network-wired"></i> MPI (Memoria Distribuida)</h3>
                        <div class="mpi-content">
                            <div class="mpi-intro">
                                <h4>¬øQu√© es MPI?</h4>
                                <p><strong>MPI (Message Passing Interface)</strong> es un est√°ndar de programaci√≥n paralela para sistemas de <strong>memoria distribuida</strong>. Permite que m√∫ltiples procesos independientes se comuniquen envi√°ndose mensajes.</p>
                                
                                <div class="concept-explanation">
                                    <h5>üîß Caracter√≠sticas Principales:</h5>
                                    <ul>
                                        <li><strong>Comunicaci√≥n por mensajes:</strong> Los procesos se comunican envi√°ndose datos expl√≠citamente</li>
                                        <li><strong>Memoria distribuida:</strong> Cada proceso tiene su propia memoria privada</li>
                                        <li><strong>Escalabilidad horizontal:</strong> Puede ejecutarse en m√∫ltiples m√°quinas conectadas por red</li>
                                        <li><strong>Independencia de procesos:</strong> Cada proceso es independiente y puede fallar sin afectar a otros</li>
                                    </ul>
                                </div>
                                
                                <div class="concept-explanation">
                                    <h5>üèóÔ∏è Arquitectura:</h5>
                                    <p>MPI funciona en sistemas donde cada procesador tiene su propia memoria. Es ideal para:</p>
                                    <ul>
                                        <li>Clusters de computadoras</li>
                                        <li>Supercomputadores distribuidos</li>
                                        <li>Grid computing (computaci√≥n en red)</li>
                                        <li>Cloud computing distribuido</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="mpi-features">
                                <h4>Funciones Principales:</h4>
                                <ul>
                                    <li><strong>MPI_Init/MPI_Finalize:</strong> Inicializar y finalizar MPI</li>
                                    <li><strong>MPI_Send/MPI_Recv:</strong> Env√≠o y recepci√≥n de mensajes</li>
                                    <li><strong>MPI_Bcast:</strong> Difusi√≥n (broadcast) de datos</li>
                                    <li><strong>MPI_Reduce:</strong> Reducci√≥n de datos entre procesos</li>
                                    <li><strong>MPI_Gather/MPI_Scatter:</strong> Recolecci√≥n y distribuci√≥n de datos</li>
                                </ul>
                            </div>
                            <div class="code-example">
                                <h4>Ejemplo 1: Suma Distribuida de un Vector</h4>
                                <div class="example-context">
                                    <h5>üìã Enunciado:</h5>
                                    <p>Calcular la suma de un vector de N elementos distribuido entre P procesos usando MPI. El proceso 0 debe mostrar el resultado final.</p>
                                </div>
                                <div class="code-block">
                                    <code>
                                        #include &lt;mpi.h&gt;<br>
                                        #include &lt;stdio.h&gt;<br>
                                        #include &lt;stdlib.h&gt;<br><br>
                                        #define N 1000000<br><br>
                                        int main(int argc, char *argv[]) {<br>
                                        &nbsp;&nbsp;int rank, size, i;<br>
                                        &nbsp;&nbsp;int *vector, *local_vector;<br>
                                        &nbsp;&nbsp;int local_size, local_sum = 0, global_sum = 0;<br>
                                        &nbsp;&nbsp;double start_time, end_time;<br><br>
                                        &nbsp;&nbsp;MPI_Init(&argc, &argv);<br>
                                        &nbsp;&nbsp;MPI_Comm_rank(MPI_COMM_WORLD, &rank);<br>
                                        &nbsp;&nbsp;MPI_Comm_size(MPI_COMM_WORLD, &size);<br><br>
                                        &nbsp;&nbsp;local_size = N / size;<br>
                                        &nbsp;&nbsp;local_vector = (int*)malloc(local_size * sizeof(int));<br><br>
                                        &nbsp;&nbsp;if(rank == 0) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;vector = (int*)malloc(N * sizeof(int));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vector[i] = rand() % 100;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;start_time = MPI_Wtime();<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;// Distribuir datos<br>
                                        &nbsp;&nbsp;MPI_Scatter(vector, local_size, MPI_INT, local_vector, local_size, MPI_INT, 0, MPI_COMM_WORLD);<br><br>
                                        &nbsp;&nbsp;// Calcular suma local<br>
                                        &nbsp;&nbsp;for(i = 0; i &lt; local_size; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;local_sum += local_vector[i];<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;// Reducir suma global<br>
                                        &nbsp;&nbsp;MPI_Reduce(&local_sum, &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);<br><br>
                                        &nbsp;&nbsp;if(rank == 0) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;end_time = MPI_Wtime();<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;printf("Suma total: %d\n", global_sum);<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;printf("Tiempo de ejecuci√≥n: %f segundos\n", end_time - start_time);<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;printf("Procesos utilizados: %d\n", size);<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;free(vector);<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;free(local_vector);<br>
                                        &nbsp;&nbsp;MPI_Finalize();<br>
                                        &nbsp;&nbsp;return 0;<br>
                                        }
                                    </code>
                                </div>
                                <div class="explanation">
                                    <h5>üîç Explicaci√≥n Detallada:</h5>
                                    <ul>
                                        <li><strong>MPI_Scatter:</strong> Distribuye el vector completo desde el proceso 0 a todos los procesos</li>
                                        <li><strong>MPI_Reduce:</strong> Suma todas las sumas locales y env√≠a el resultado al proceso 0</li>
                                        <li><strong>MPI_Wtime():</strong> Funci√≥n de MPI para medir tiempo de ejecuci√≥n</li>
                                        <li><strong>Distribuci√≥n de trabajo:</strong> Cada proceso calcula la suma de su porci√≥n del vector</li>
                                        <li><strong>Ventaja:</strong> Escalabilidad horizontal - m√°s procesos = mejor rendimiento</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="code-example">
                                <h4>Ejemplo 2: Multiplicaci√≥n de Matrices Distribuida</h4>
                                <div class="example-context">
                                    <h5>üìã Enunciado:</h5>
                                    <p>Implementar la multiplicaci√≥n de matrices A√óB=C distribuyendo las filas de A entre los procesos. Cada proceso calcula sus filas correspondientes de C.</p>
                                </div>
                                <div class="code-block">
                                    <code>
                                        #include &lt;mpi.h&gt;<br>
                                        #include &lt;stdio.h&gt;<br>
                                        #include &lt;stdlib.h&gt;<br><br>
                                        #define N 512<br><br>
                                        int main(int argc, char *argv[]) {<br>
                                        &nbsp;&nbsp;int rank, size, i, j, k;<br>
                                        &nbsp;&nbsp;int rows_per_proc, start_row, end_row;<br>
                                        &nbsp;&nbsp;double **A, **B, **C;<br>
                                        &nbsp;&nbsp;double *local_A, *local_C;<br>
                                        &nbsp;&nbsp;double start_time, end_time;<br><br>
                                        &nbsp;&nbsp;MPI_Init(&argc, &argv);<br>
                                        &nbsp;&nbsp;MPI_Comm_rank(MPI_COMM_WORLD, &rank);<br>
                                        &nbsp;&nbsp;MPI_Comm_size(MPI_COMM_WORLD, &size);<br><br>
                                        &nbsp;&nbsp;rows_per_proc = N / size;<br>
                                        &nbsp;&nbsp;start_row = rank * rows_per_proc;<br>
                                        &nbsp;&nbsp;end_row = start_row + rows_per_proc;<br><br>
                                        &nbsp;&nbsp;if(rank == 0) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;// Inicializar matrices completas en proceso 0<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;A = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;B = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;C = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;// Inicializar con valores<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for(j = 0; j &lt; N; j++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A[i][j] = 1.0;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B[i][j] = 1.0;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;start_time = MPI_Wtime();<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;// Distribuir filas de A<br>
                                        &nbsp;&nbsp;local_A = (double*)malloc(rows_per_proc * N * sizeof(double));<br>
                                        &nbsp;&nbsp;local_C = (double*)malloc(rows_per_proc * N * sizeof(double));<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;MPI_Scatter(A[0], rows_per_proc * N, MPI_DOUBLE, local_A, rows_per_proc * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);<br>
                                        &nbsp;&nbsp;<br>
                                        &nbsp;&nbsp;// Broadcast matriz B a todos los procesos<br>
                                        &nbsp;&nbsp;if(rank != 0) B = (double**)malloc(N * sizeof(double*));<br>
                                        &nbsp;&nbsp;if(rank != 0) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(i = 0; i &lt; N; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B[i] = (double*)malloc(N * sizeof(double));<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;MPI_Bcast(B[0], N * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);<br><br>
                                        &nbsp;&nbsp;// Multiplicaci√≥n local<br>
                                        &nbsp;&nbsp;for(i = 0; i &lt; rows_per_proc; i++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(j = 0; j &lt; N; j++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;local_C[i * N + j] = 0.0;<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for(k = 0; k &lt; N; k++) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;local_C[i * N + j] += local_A[i * N + k] * B[k][j];<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;// Recopilar resultados<br>
                                        &nbsp;&nbsp;MPI_Gather(local_C, rows_per_proc * N, MPI_DOUBLE, C[0], rows_per_proc * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);<br><br>
                                        &nbsp;&nbsp;if(rank == 0) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;end_time = MPI_Wtime();<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;printf("Tiempo de ejecuci√≥n: %f segundos\n", end_time - start_time);<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;printf("Procesos utilizados: %d\n", size);<br>
                                        &nbsp;&nbsp;}<br><br>
                                        &nbsp;&nbsp;free(local_A); free(local_C);<br>
                                        &nbsp;&nbsp;if(rank != 0) {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;for(i = 0; i &lt; N; i++) free(B[i]);<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;free(B);<br>
                                        &nbsp;&nbsp;}<br>
                                        &nbsp;&nbsp;MPI_Finalize();<br>
                                        &nbsp;&nbsp;return 0;<br>
                                        }
                                    </code>
                                </div>
                                <div class="explanation">
                                    <h5>üîç Explicaci√≥n Detallada:</h5>
                                    <ul>
                                        <li><strong>MPI_Scatter:</strong> Distribuye filas de A entre procesos</li>
                                        <li><strong>MPI_Bcast:</strong> Env√≠a matriz B completa a todos los procesos</li>
                                        <li><strong>MPI_Gather:</strong> Recopila resultados de todos los procesos</li>
                                        <li><strong>Distribuci√≥n por filas:</strong> Cada proceso calcula filas espec√≠ficas de C</li>
                                        <li><strong>Comunicaci√≥n colectiva:</strong> Uso eficiente de operaciones MPI para distribuci√≥n de datos</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card comparison-card">
                        <h3><i class="fas fa-balance-scale"></i> OpenMP vs MPI: Comparaci√≥n</h3>
                        <div class="comparison-content">
                            <div class="comparison-table">
                                <table>
                                    <thead>
                                        <tr>
                                            <th>Caracter√≠stica</th>
                                            <th>OpenMP</th>
                                            <th>MPI</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td><strong>Modelo de Memoria</strong></td>
                                            <td>Memoria Compartida</td>
                                            <td>Memoria Distribuida</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Unidad de Trabajo</strong></td>
                                            <td>Hilos (Threads)</td>
                                            <td>Procesos (Processes)</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Comunicaci√≥n</strong></td>
                                            <td>Impl√≠cita (memoria compartida)</td>
                                            <td>Expl√≠cita (mensajes)</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Escalabilidad</strong></td>
                                            <td>Vertical (m√∫ltiples n√∫cleos)</td>
                                            <td>Horizontal (m√∫ltiples m√°quinas)</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Facilidad de Uso</strong></td>
                                            <td>F√°cil (directivas del compilador)</td>
                                            <td>Moderada (gesti√≥n de comunicaci√≥n)</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Rendimiento</strong></td>
                                            <td>Alto (acceso directo a memoria)</td>
                                            <td>Alto (paralelismo masivo)</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Casos de Uso</strong></td>
                                            <td>Algoritmos con dependencias de datos</td>
                                            <td>Problemas masivamente paralelos</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                            
                            <div class="comparison-summary">
                                <h4>üìä Resumen de Diferencias:</h4>
                                <div class="summary-grid">
                                    <div class="summary-item openmp-summary">
                                        <h5><i class="fas fa-microchip"></i> OpenMP</h5>
                                        <p><strong>Mejor para:</strong> Programas que necesitan compartir datos frecuentemente entre hilos, algoritmos con dependencias complejas, desarrollo r√°pido de prototipos.</p>
                                        <p><strong>Limitaciones:</strong> Limitado a una sola m√°quina, n√∫mero limitado de hilos.</p>
                                    </div>
                                    <div class="summary-item mpi-summary">
                                        <h5><i class="fas fa-network-wired"></i> MPI</h5>
                                        <p><strong>Mejor para:</strong> Problemas que se pueden dividir en partes independientes, computaci√≥n masivamente paralela, clusters de computadoras.</p>
                                        <p><strong>Limitaciones:</strong> M√°s complejo de programar, comunicaci√≥n expl√≠cita requerida.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card patterns-card">
                        <h3><i class="fas fa-puzzle-piece"></i> Patrones de Algoritmos Paralelos</h3>
                        <div class="patterns-list">
                            <div class="pattern-item">
                                <h4><i class="fas fa-map"></i> Map-Reduce</h4>
                                <p>Procesamiento de datos distribuido en dos fases</p>
                                <div class="pattern-example">
                                    <strong>Fase Map:</strong> Aplicar funci√≥n a cada elemento<br>
                                    <strong>Fase Reduce:</strong> Combinar resultados parciales
                                </div>
                            </div>
                            <div class="pattern-item">
                                <h4><i class="fas fa-cut"></i> Divide y Vencer√°s</h4>
                                <p>Divisi√≥n recursiva del problema en subproblemas</p>
                                <div class="pattern-example">
                                    <strong>Divide:</strong> Dividir problema en subproblemas<br>
                                    <strong>Conquista:</strong> Resolver subproblemas recursivamente<br>
                                    <strong>Combina:</strong> Combinar soluciones
                                </div>
                            </div>
                            <div class="pattern-item">
                                <h4><i class="fas fa-stream"></i> Pipeline</h4>
                                <p>Procesamiento en etapas secuenciales</p>
                                <div class="pattern-example">
                                    <strong>Etapa 1:</strong> Lectura de datos<br>
                                    <strong>Etapa 2:</strong> Procesamiento<br>
                                    <strong>Etapa 3:</strong> Escritura de resultados
                                </div>
                            </div>
                            <div class="pattern-item">
                                <h4><i class="fas fa-users"></i> Farm/Worker</h4>
                                <p>Distribuci√≥n de tareas entre trabajadores</p>
                                <div class="pattern-example">
                                    <strong>Master:</strong> Distribuye tareas<br>
                                    <strong>Workers:</strong> Procesan tareas asignadas<br>
                                    <strong>Resultados:</strong> Recopilaci√≥n de resultados
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card tools-card">
                        <h3><i class="fas fa-tools"></i> Herramientas de Desarrollo</h3>
                        <div class="tools-list">
                            <div class="tool-item">
                                <h4><i class="fas fa-chart-line"></i> Profiling Tools</h4>
                                <div class="tool-details">
                                    <strong>Intel VTune:</strong> An√°lisis de rendimiento avanzado<br>
                                    <strong>NVIDIA Nsight:</strong> Profiling para GPU<br>
                                    <strong>gprof:</strong> Profiling b√°sico de CPU<br>
                                    <strong>Valgrind:</strong> Detecci√≥n de memory leaks
                                </div>
                            </div>
                            <div class="tool-item">
                                <h4><i class="fas fa-bug"></i> Debugging</h4>
                                <div class="tool-details">
                                    <strong>GDB:</strong> Debugger con soporte multi-hilo<br>
                                    <strong>TotalView:</strong> Debugger para HPC<br>
                                    <strong>DDT:</strong> Debugger de Allinea<br>
                                    <strong>Intel Inspector:</strong> Detecci√≥n de errores
                                </div>
                            </div>
                            <div class="tool-item">
                                <h4><i class="fas fa-chart-bar"></i> Performance Analysis</h4>
                                <div class="tool-details">
                                    <strong>Intel Advisor:</strong> An√°lisis de vectorizaci√≥n<br>
                                    <strong>AMD uProf:</strong> Profiling de AMD<br>
                                    <strong>Score-P:</strong> Instrumentaci√≥n autom√°tica<br>
                                    <strong>TAU:</strong> Toolkit de an√°lisis
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Optimizaci√≥n Section -->
            <section id="optimizacion" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-tachometer-alt"></i> Optimizaci√≥n de Rendimiento</h2>
                    <p>T√©cnicas avanzadas para mejorar el rendimiento de aplicaciones paralelas</p>
                </div>
                
                <div class="content-grid">
                    <div class="card load-balancing-card">
                        <h3><i class="fas fa-balance-scale"></i> Load Balancing</h3>
                        <div class="load-balancing-content">
                            <h4>Estrategias de Balanceo:</h4>
                            <div class="strategy-list">
                                <div class="strategy-item">
                                    <h5>Est√°tico</h5>
                                    <p>Distribuci√≥n fija de tareas al inicio</p>
                                    <ul>
                                        <li>Round-robin</li>
                                        <li>Distribuci√≥n por peso</li>
                                        <li>Distribuci√≥n por capacidad</li>
                                    </ul>
                                </div>
                                <div class="strategy-item">
                                    <h5>Din√°mico</h5>
                                    <p>Ajuste de carga durante la ejecuci√≥n</p>
                                    <ul>
                                        <li>Work stealing</li>
                                        <li>Work sharing</li>
                                        <li>Adaptativo</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card cache-coherence-card">
                        <h3><i class="fas fa-sync"></i> Protocolos de Coherencia de Cach√©</h3>
                        <div class="coherence-protocols">
                            <div class="protocol-detail">
                                <h4>MSI (Modified, Shared, Invalid)</h4>
                                <div class="protocol-states">
                                    <div class="state-item">
                                        <strong>Modified:</strong> L√≠nea modificada, solo en este cach√©
                                    </div>
                                    <div class="state-item">
                                        <strong>Shared:</strong> L√≠nea v√°lida, posiblemente en otros cach√©s
                                    </div>
                                    <div class="state-item">
                                        <strong>Invalid:</strong> L√≠nea no v√°lida
                                    </div>
                                </div>
                            </div>
                            <div class="protocol-detail">
                                <h4>MESI (Modified, Exclusive, Shared, Invalid)</h4>
                                <div class="protocol-states">
                                    <div class="state-item">
                                        <strong>Modified:</strong> L√≠nea modificada, solo en este cach√©
                                    </div>
                                    <div class="state-item">
                                        <strong>Exclusive:</strong> L√≠nea v√°lida, solo en este cach√©
                                    </div>
                                    <div class="state-item">
                                        <strong>Shared:</strong> L√≠nea v√°lida, en m√∫ltiples cach√©s
                                    </div>
                                    <div class="state-item">
                                        <strong>Invalid:</strong> L√≠nea no v√°lida
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card false-sharing-card">
                        <h3><i class="fas fa-exclamation-triangle"></i> False Sharing</h3>
                        <div class="false-sharing-content">
                            <h4>Problema:</h4>
                            <p>M√∫ltiples hilos acceden a variables diferentes en la misma l√≠nea de cach√©, causando invalidaciones innecesarias.</p>
                            
                            <div class="false-sharing-example">
                                <h4>Ejemplo Problem√°tico:</h4>
                                <div class="code-block">
                                    <code>
                                        struct Data {<br>
                                        &nbsp;&nbsp;int counter1;  // Hilo 1 modifica<br>
                                        &nbsp;&nbsp;int counter2;  // Hilo 2 modifica<br>
                                        } data;
                                    </code>
                                </div>
                                
                                <h4>Soluci√≥n - Padding:</h4>
                                <div class="code-block">
                                    <code>
                                        struct Data {<br>
                                        &nbsp;&nbsp;int counter1;<br>
                                        &nbsp;&nbsp;char padding[64];  // Padding para separar l√≠neas<br>
                                        &nbsp;&nbsp;int counter2;<br>
                                        } data;
                                    </code>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card memory-hierarchy-card">
                        <h3><i class="fas fa-layer-group"></i> Optimizaci√≥n de Jerarqu√≠a de Memoria</h3>
                        <div class="memory-optimization">
                            <h4>T√©cnicas de Optimizaci√≥n:</h4>
                            <div class="optimization-techniques">
                                <div class="technique-item">
                                    <h5><i class="fas fa-memory"></i> Localidad Espacial</h5>
                                    <p>Acceder a datos contiguos en memoria</p>
                                    <div class="technique-example">
                                        <code>// Bueno: Acceso secuencial<br>for(i=0; i&lt;n; i++) sum += array[i];</code>
                                    </div>
                                </div>
                                <div class="technique-item">
                                    <h5><i class="fas fa-clock"></i> Localidad Temporal</h5>
                                    <p>Reutilizar datos recientemente accedidos</p>
                                    <div class="technique-example">
                                        <code>// Bueno: Reutilizar variables<br>int temp = compute();<br>result = temp * temp;</code>
                                    </div>
                                </div>
                                <div class="technique-item">
                                    <h5><i class="fas fa-compress"></i> Prefetching</h5>
                                    <p>Cargar datos antes de necesitarlos</p>
                                    <div class="technique-example">
                                        <code>// Prefetch manual<br>__builtin_prefetch(&array[i+1], 1, 3);</code>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card optimization-tools-card">
                        <h3><i class="fas fa-wrench"></i> Herramientas de Optimizaci√≥n</h3>
                        <div class="optimization-tools">
                            <div class="tool-category">
                                <h4><i class="fas fa-chart-line"></i> Profiling Avanzado</h4>
                                <div class="tool-list">
                                    <div class="tool-item">
                                        <strong>Intel VTune Profiler:</strong> An√°lisis detallado de CPU y memoria
                                    </div>
                                    <div class="tool-item">
                                        <strong>AMD uProf:</strong> Profiling espec√≠fico para procesadores AMD
                                    </div>
                                    <div class="tool-item">
                                        <strong>NVIDIA Nsight Compute:</strong> An√°lisis de kernels CUDA
                                    </div>
                                </div>
                            </div>
                            <div class="tool-category">
                                <h4><i class="fas fa-bug"></i> Detecci√≥n de Problemas</h4>
                                <div class="tool-list">
                                    <div class="tool-item">
                                        <strong>Intel Inspector:</strong> Detecci√≥n de race conditions
                                    </div>
                                    <div class="tool-item">
                                        <strong>Valgrind Helgrind:</strong> Detecci√≥n de problemas de concurrencia
                                    </div>
                                    <div class="tool-item">
                                        <strong>ThreadSanitizer:</strong> Detecci√≥n de data races
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card performance-metrics-card">
                        <h3><i class="fas fa-chart-bar"></i> M√©tricas de Rendimiento</h3>
                        <div class="metrics-content">
                            <h4>M√©tricas Clave:</h4>
                            <div class="metric-categories">
                                <div class="metric-category">
                                    <h5>Eficiencia</h5>
                                    <ul>
                                        <li>Speedup: S(p) = T(1) / T(p)</li>
                                        <li>Eficiencia: E(p) = S(p) / p</li>
                                        <li>Escalabilidad: Crecimiento del problema</li>
                                    </ul>
                                </div>
                                <div class="metric-category">
                                    <h5>Comunicaci√≥n</h5>
                                    <ul>
                                        <li>Overhead de comunicaci√≥n</li>
                                        <li>Latencia de red</li>
                                        <li>Ancho de banda utilizado</li>
                                    </ul>
                                </div>
                                <div class="metric-category">
                                    <h5>Memoria</h5>
                                    <ul>
                                        <li>Cache hit ratio</li>
                                        <li>Memory bandwidth</li>
                                        <li>False sharing</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Ejemplos Section -->
            <section id="ejemplos" class="content-section">
                <div class="section-header">
                    <h2><i class="fas fa-flask"></i> Ejemplos Pr√°cticos</h2>
                    <p>Aplicaciones y casos de uso de computadores paralelos</p>
                </div>
                
                <div class="content-grid">
                    <div class="card applications-card">
                        <h3><i class="fas fa-cogs"></i> Aplicaciones T√≠picas</h3>
                        <div class="applications-list">
                            <div class="application-item">
                                <i class="fas fa-atom"></i>
                                <h4>Simulaciones Cient√≠ficas</h4>
                                <p>Modelado de fen√≥menos f√≠sicos complejos</p>
                                <ul>
                                    <li>Din√°mica de fluidos</li>
                                    <li>Simulaciones clim√°ticas</li>
                                    <li>F√≠sica de part√≠culas</li>
                                </ul>
                            </div>
                            <div class="application-item">
                                <i class="fas fa-dna"></i>
                                <h4>Bioinform√°tica</h4>
                                <p>An√°lisis de secuencias gen√©ticas</p>
                                <ul>
                                    <li>Alineamiento de secuencias</li>
                                    <li>Predicci√≥n de estructuras</li>
                                    <li>An√°lisis de prote√≠nas</li>
                                </ul>
                            </div>
                            <div class="application-item">
                                <i class="fas fa-image"></i>
                                <h4>Procesamiento de Im√°genes</h4>
                                <p>An√°lisis y manipulaci√≥n de im√°genes</p>
                                <ul>
                                    <li>Reconocimiento de patrones</li>
                                    <li>Filtrado de im√°genes</li>
                                    <li>Compresi√≥n de video</li>
                                </ul>
                            </div>
                            <div class="application-item">
                                <i class="fas fa-database"></i>
                                <h4>Miner√≠a de Datos</h4>
                                <p>An√°lisis de grandes vol√∫menes de datos</p>
                                <ul>
                                    <li>Machine Learning</li>
                                    <li>An√°lisis predictivo</li>
                                    <li>Procesamiento de Big Data</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="card benchmarks-card">
                        <h3><i class="fas fa-vial"></i> Benchmarks Paralelos</h3>
                        <div class="benchmarks-list">
                            <div class="benchmark-item">
                                <h4>SPEC OMP2012</h4>
                                <p>Benchmark para aplicaciones OpenMP</p>
                                <div class="benchmark-details">
                                    <strong>Caracter√≠sticas:</strong>
                                    <ul>
                                        <li>12 aplicaciones reales</li>
                                        <li>Paralelismo de memoria compartida</li>
                                        <li>M√©tricas de speedup y eficiencia</li>
                                    </ul>
                                </div>
                            </div>
                            <div class="benchmark-item">
                                <h4>SPEC MPI2007</h4>
                                <p>Benchmark para aplicaciones MPI</p>
                                <div class="benchmark-details">
                                    <strong>Caracter√≠sticas:</strong>
                                    <ul>
                                        <li>13 aplicaciones reales</li>
                                        <li>Paralelismo de memoria distribuida</li>
                                        <li>Escalabilidad de aplicaciones</li>
                                    </ul>
                                </div>
                            </div>
                            <div class="benchmark-item">
                                <h4>HPCC (HPC Challenge)</h4>
                                <p>Suite de benchmarks para HPC</p>
                                <div class="benchmark-details">
                                    <strong>Caracter√≠sticas:</strong>
                                    <ul>
                                        <li>7 kernels de prueba</li>
                                        <li>M√©tricas de ancho de banda</li>
                                        <li>Latencia de comunicaci√≥n</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="content-grid">
                    <div class="card simulator-card">
                        <h3><i class="fas fa-play"></i> Simulador de Speedup</h3>
                        <div class="simulator">
                            <div class="simulator-controls">
                                <div class="control-group">
                                    <label for="sim-parallel-fraction">Fracci√≥n Paralelizable:</label>
                                    <input type="range" id="sim-parallel-fraction" min="0" max="1" step="0.01" value="0.8">
                                    <span id="sim-parallel-fraction-display">0.8</span>
                                </div>
                                <div class="control-group">
                                    <label for="sim-max-processors">M√°ximo Procesadores:</label>
                                    <input type="range" id="sim-max-processors" min="2" max="128" value="32">
                                    <span id="sim-max-processors-display">32</span>
                                </div>
                                <button class="btn btn-primary" onclick="runSpeedupSimulation()">
                                    <i class="fas fa-play"></i>
                                    Ejecutar Simulaci√≥n
                                </button>
                            </div>
                            <div class="simulation-results">
                                <div class="result-chart">
                                    <canvas id="speedupChart" width="400" height="200"></canvas>
                                </div>
                                <div class="result-stats">
                                    <div class="stat-item">
                                        <strong>Speedup M√°ximo:</strong> <span id="max-speedup">-</span>x
                                    </div>
                                    <div class="stat-item">
                                        <strong>Eficiencia M√°xima:</strong> <span id="max-efficiency">-</span>%
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card examples-card">
                        <h3><i class="fas fa-code"></i> Ejemplos de C√≥digo</h3>
                        <div class="code-examples">
                            <div class="code-example">
                                <h4>OpenMP (Memoria Compartida)</h4>
                                <div class="code-block">
                                    <code>
                                        #pragma omp parallel for<br>
                                        for (int i = 0; i < n; i++) {<br>
                                        &nbsp;&nbsp;result[i] = compute(data[i]);<br>
                                        }
                                    </code>
                                </div>
                            </div>
                            <div class="code-example">
                                <h4>MPI (Memoria Distribuida)</h4>
                                <div class="code-block">
                                    <code>
                                        MPI_Init(&argc, &argv);<br>
                                        MPI_Comm_rank(MPI_COMM_WORLD, &rank);<br>
                                        MPI_Comm_size(MPI_COMM_WORLD, &size);<br>
                                        // ... procesamiento paralelo ...<br>
                                        MPI_Finalize();
                                    </code>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
        </main>
    </div>

    <script src="script.js"></script>
</body>
</html>
