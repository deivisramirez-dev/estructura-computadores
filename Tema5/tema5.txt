Tema 5

Estructura de Computadores

Procesadores
segmentados

√çndice
Esquema

3

Ideas clave

4

5.1. Introducci√≥n y objetivos

4

5.2. Introducci√≥n

4

¬© Universidad Internacional de La Rioja (UNIR)

5.3. Principios de segmentaci√≥n y mejora de
prestaciones

7

5.4. Dise√±o de un procesador segmentado

9

5.5. Optimizaci√≥n de causes funcionales

16

5.6. Interrupciones en un procesador segmentado 17
5.7. Referencias bibliogr√°ficas

19

A fondo

20

Actividades

22

Test

23

¬© Universidad Internacional de La Rioja (UNIR)

Tr a t a m i e n t o d e
i n ter r u p c i o n es en
p r o c es a d o r es
s egmen ta d o s

O p ti mi za c i √≥ n d e
c a u c es

D i s e√± o d e u n
p r o c es a d o r
s egmen ta d o

Pri nci pios de l a
s egmen ta c i √≥ n y
mej o r a d e
p r es ta c i o n es

I n tr od u c c i √≥n

No lineales

Lineales

Alternativas de dise√±o de un procesador
segmentado

Instrucciones de acceso a memoria

Instrucciones de salto

Soluciones a conflictos RAW

Otros par√°metros

Aceleraci√≥n

Tiempo de llenado

Referencias hist√≥ricas

Conceptos b√°sicos sobre procesadores escalares

Esquema

Estructura de Computadores
Tema 5. Esquema

3

P R O C E S A D O R E S S E G ME N TA D O S

Ideas clave
5.1. Introducci√≥n y objetivos
Para estudiar este tema lee las ideas clave que se desarrollan a continuaci√≥n.

En este tema se presenta el concepto de segmentaci√≥n de cauce (pipelining), t√©cnica
de paralelismo aplicable en diferentes fases del dise√±o hardware de un computador
y que permite aumentar su rendimiento.

Haremos especial hincapi√© en la aplicaci√≥n a los procesadores segmentados, cuya
microarquitectura se desarrolla aplicando estas t√©cnicas, lo que le permite ejecutar
varias instrucciones simult√°neamente, aunque sea en distintas fases de ejecuci√≥n.

En estos casos se dice que el procesador aprovecha el paralelismo entre
instrucciones o a nivel de instrucci√≥n (ILP, Instruction Level Parallelism).

La implementaci√≥n de estos cauces de ejecuci√≥n simult√°nea provoca una serie de
conflictos (dependencias), inherentes a la propia t√©cnica, que limitar√°n la eficiencia
de la estructura y cuyos efectos ser√° necesario paliar en el dise√±o de un procesador
segmentado.

¬© Universidad Internacional de La Rioja (UNIR)

5.2. Introducci√≥n
La t√©cnica de segmentaci√≥n de cauce (pipelining) consiste en dividir el proceso
(instrucci√≥n, operaci√≥n) que debe realizar el sistema en una serie de fases o pasos, y
en redise√±ar el propio sistema, de modo que pase a estar constituido por una cadena

Estructura de Computadores
Tema 5. Ideas clave

4

de unidades funcionales donde, cada una de ellas estar√° encargada de realizar cada
fase o paso del proceso de forma independiente.

En esas condiciones, idealmente, en el sistema habr√° tantos procesos en curso como
unidades funcionales, aunque cada uno de ellos estar√° ejecutando una fase
diferente.

Con esta t√©cnica no tiene porqu√© mejorar el tiempo de ejecuci√≥n de un proceso
aislado pero, mientras se mantengan llenas todas las unidades funcionales, s√≠ se
obtendr√°n m√°s procesos finalizados por unidad de tiempo, se juega con el
solapamiento de los tiempos de ejecuci√≥n de los distintos procesos.

La idea viene de la cadena de producci√≥n en serie implantada en la fabricaci√≥n de
autom√≥viles a comienzos del siglo XX.

La conexi√≥n en paralelo de cadenas de unidades funcionales (cadenas pipeline)
constituir√° la base de los procesadores superescalares.

La figura 1 esquematiza la t√©cnica considerando instrucciones que se pueden dividir
en cinco fases [Instruction Fetch (IF), Instruction Decode (ID), Instruction Execution

¬© Universidad Internacional de La Rioja (UNIR)

(EX), Memory Access (MEM) y WriteBack (WB)] de igual duraci√≥n (T).

Estructura de Computadores
Tema 5. Ideas clave

5

Figura 1. Cronogramas de ejecuci√≥n de un procesador secuencial, segmentado y superescalar.
Fuente: Ortega et al., 2005.

Breve secuencia hist√≥rica
La segmentaci√≥n de cauce se propuso inicialmente para acelerar las operaciones en
coma flotante.

El primer computador que implement√≥ segmentaci√≥n de cauce (proyecto Stretch)
fue el IBM 7030 (1961). Ten√≠a por objetivo ser 100 veces m√°s r√°pido que su
predecesor, el IBM 704.

En los 70 se aplica de forma habitual en el desarrollo de procesadores vectoriales y

¬© Universidad Internacional de La Rioja (UNIR)

se extiende al procesamiento de instrucciones.

A principios de los 80, la implantaci√≥n de las cadenas pipeline en los procesadores
fue uno de los motivos esenciales de la aparici√≥n de las arquitecturas RISC (Reduced,
Instruction Set Computer), en oposici√≥n a las arquitecturas CISC (Complex Instruction
Set Computer) existentes en el momento, que no aprovechaban adecuadamente las
mejoras de rendimiento que la segmentaci√≥n de cauce aportaba al procesador.

Estructura de Computadores
Tema 5. Ideas clave

6

A partir de mediados de los 80, los microprocesadores incorporan la segmentaci√≥n
de cauce, y a partir del comienzo de los 90 la segmentaci√≥n de cauce se introduce
tambi√©n en los micros embebidos o empotrados (microcontroladores), que
requieren prestaciones elevadas.

5.3. Principios de segmentaci√≥n y mejora de
prestaciones
Supongamos un procesador secuencial que ejecute una instrucci√≥n en un tiempo T,
si su ejecuci√≥n fuese uniforme, tardar√≠a un tiempo ùëõ ùë• ùëá en ejecutar n instrucciones.

Aplicando la segmentaci√≥n de cauce, en un caso ideal, se dividir√≠a la instrucci√≥n en
fases de duraci√≥n t, que se ejecutasen en sendas unidades funcionales
independientes conectadas en cascada de modo que, tras la primera instrucci√≥n
ejecutada, se obtendr√≠a una instrucci√≥n finalizada cada tiempo t (figura 2).

La primera instrucci√≥n tardar√≠a un tiempo completo de proceso, que coincidir√≠a con
el tiempo de llenado de la cadena y que se designa como TLI (Tiempo de Latencia de

¬© Universidad Internacional de La Rioja (UNIR)

inicio).

Estructura de Computadores
Tema 5. Ideas clave

7

Figura 2. Comparaci√≥n del ejemplo propuesto. Fuente: Ortega et al., 2005.

La aceleraci√≥n o ganancia obtenida por el sistema al aplicar esta t√©cnica a la ejecuci√≥n
de n instrucciones ser√≠a:

S(n) =

Tsin _segmentar
Tsegmentado

n√óT

= TLI+(n‚àí1)√ót

[5.1]

Cuyo m√°ximo se obtendr√≠a para un n√∫mero infinito de instrucciones:

Smax = lim S(n) =
n‚Üí‚àû

T
t

[5.2]

¬© Universidad Internacional de La Rioja (UNIR)

Cuanto menor sea t, mayor ser√° la ganancia obtenida, al relacionar t con el n√∫mero
de etapas o unidades, k, en principio a mayor n√∫mero de etapas, mayor ganancia
(suponiendo etapas m√°s simples que implican t menor).

Se podr√≠a expresar ùëáùêøùêº = ùëò ùë• ùë°, incluso, de forma ideal, TLI = T. En estas condiciones,
la ganancia obtenida se podr√≠a presentar como:

Estructura de Computadores
Tema 5. Ideas clave

8

S(n) =

Tsin segmentar
n√ók√ót
n√ók
=
=
Tsegmentado
k √ó t + (n ‚àí l) √ó t k + n ‚àí l
[5.3]

Desviaciones m√°s habituales respecto al caso ideal:

ÔÇÑ TLI = k√ót > T
ÔÇÑ El tiempo de etapa t no es com√∫n en todas ellas, la m√°s lenta es la que marca el

comportamiento del sistema (registro de desacoplo, cuello de botella).

Otras magnitudes a considerar:

ÔÇÑ Productividad (W): n√∫mero de operaciones que se ejecutan por unidad de tiempo.

Para n operaciones ejecutadas:

W(n) =

n
TLI + (n ‚àí l) √ó t
[5.4]

ÔÇÑ Eficiencia (Ek): relaci√≥n entre la ganancia o aceleraci√≥n que proporciona el cauce

y el n√∫mero de etapas:

Ek (n) =

n√óT
k √ó [TLI + (n ‚àí l) √ó t
[5.5]

¬© Universidad Internacional de La Rioja (UNIR)

5.4. Dise√±o de un procesador segmentado
Este apartado busca presentar las complicaciones que aparecen al ejecutar
instrucciones en un procesador segmentado.

Estructura de Computadores
Tema 5. Ideas clave

9

En el manual de la asignatura se parte de un caso muy simple de procesador que
responde a las siguientes premisas:

ÔÇÑ Procesador de 32 bits.
ÔÇÑ Instrucci√≥n sencilla del tipo Ra op Rb ‚Üí Rc.
ÔÇÑ Ra, Rb y Rc son registros de un banco de registros con dos puertos de lectura y uno

de escritura.

Estos requisitos llevan a un cauce de cuatro etapas:

ÔÇÑ Captaci√≥n de instrucci√≥n (IF).
ÔÇÑ Decodificaci√≥n/Lectura de operandos (ID/OF).
ÔÇÑ Ejecuci√≥n de la operaci√≥n (ALU).
ÔÇÑ Escritura de resultado en el banco de registros (OS).

¬© Universidad Internacional de La Rioja (UNIR)

Y a una configuraci√≥n como la que se representa en la figura 3.

Figura 3. Cauce y arquitectura del procesador segmentado b√°sico. Fuente: Ortega et al., 2005.

Estructura de Computadores
Tema 5. Ideas clave

10

En estas condiciones cada instrucci√≥n requerir√≠a cuatro ciclos para procesarse y se
obtendr√≠a una instrucci√≥n procesada por ciclo, a partir de la primera.

Suponiendo ahora que se ejecuta la siguiente secuencia de instrucciones:

Teniendo en cuenta el cauce utilizado, se producir√≠a un conflicto en la ejecuci√≥n de
las instrucciones (2) y (3) en relaci√≥n con el operando R3 (figura 4). Se trata de un
conflicto por dependencia de lectura tras escritura o de tipo RAW (Read After
Write).

Figura 4. Dependencia de lectura tras escritura (RAW). Fuente: Ortega et al., 2005.

¬© Universidad Internacional de La Rioja (UNIR)

Riesgo, conflicto o dependencia (hazard) es cualquier condici√≥n que puede
interrumpir el flujo continuo a trav√©s de un cauce. Pueden ser:

ÔÇÑ Riesgos de Datos: dependencias entre los operandos y resultados de instrucciones

distintas. A su vez pueden ser:
‚Ä¢ RAW (Read After Write) o dependencia de lectura tras escritura.

Estructura de Computadores
Tema 5. Ideas clave

11

‚Ä¢ WAR (Write After Read) o dependencia de escritura tras lectura.
‚Ä¢ WAW (Write After Write) o dependencia de escritura tras escritura.
ÔÇÑ Riesgos de Control: instrucciones de salto condicional que, seg√∫n su resultado,

determinan si hay que ejecutar una secuencia de instrucciones u otra.
ÔÇÑ Riesgos Estructurales o Colisiones: distintas instrucciones necesitan el mismo

recurso al mismo tiempo.

La dependencia RAW tambi√©n se conoce como dependencia real y se puede producir
siempre que se ejecuten acciones simult√°neas y coincida esa relaci√≥n escritura‚Äî
lectura de dos instrucciones sobre un mismo operando.

Las dependencias WAR y WAW son propias de procesadores superescalares en los
que se permita la ejecuci√≥n desordenada de instrucciones. Tambi√©n se las conoce
como pseudodependencias.

Soluciones para las dependencias RAW
Existen distintos tipos de soluciones para paliar, e incluso evitar, los efectos de las
dependencias RAW. Hay que tener en cuenta que este tipo de dependencias no solo
pueden provocar p√©rdidas de rendimiento sino tambi√©n errores de ejecuci√≥n, lo cual
es mucho m√°s grave. Si se deja pasar la dependencia la instrucci√≥n dependiente lee
el operando antes de que la instrucci√≥n de la que depende lo haya actualizado lo que
producir√° un error de ejecuci√≥n.
Algunas de las soluciones requieren de elementos hardware a√±adidos y otras son

¬© Universidad Internacional de La Rioja (UNIR)

soluciones m√°s software, vinculadas al compilador.

Las opciones m√°s importantes que se deben conocer son:

ÔÇÑ Reorganizaci√≥n de c√≥digo: consiste en separar en el programa las instrucciones

dependientes, de modo que no exista conflicto. Esta t√©cnica depende del
compilador.
Estructura de Computadores
Tema 5. Ideas clave

12

ÔÇÑ Interbloqueo

entre etapas: se incluyen elementos HW de detecci√≥n de

dependencias, que permitir√°n el bloqueo de la instrucci√≥n dependiente hasta que
la anterior actualice el operando.
ÔÇÑ Atajos (bypass paths o forwarding): se aprovechan los elementos de detecci√≥n del

anterior para adelantar la actualizaci√≥n del operando dependiente.

Implementaci√≥n de instrucciones de salto
El problema que plantean las instrucciones de salto, y en general cualquier
instrucci√≥n de ruptura de secuencia (saltos condicionales o incondicionales, llamadas
a rutina, retornos, atenci√≥n a interrupciones), es que modifican el valor que toma por
defecto el registro contador de programa (PC) del procesador. Representan casos
t√≠picos de riesgos de control.
Tras cada ciclo de captaci√≥n de instrucci√≥n, el PC se incrementa autom√°ticamente
para apuntar a la siguiente posici√≥n de c√≥digo de programa a leer, en base a su
contenido se realiza la siguiente captaci√≥n. Trabajando con segmentaci√≥n de cauce,
la unidad IF usar√° como referencia el valor del PC para leer la siguiente instrucci√≥n,
pero es posible que, tras una instrucci√≥n de salto, ese valor no sea correcto puesto
que el objetivo de la instrucci√≥n es modificar PC y esto todav√≠a no se habr√° llevado a
cabo. En otras palabras, la unidad IF tarda tantas instrucciones en ¬´darse cuenta¬ª de
que se ha saltado como unidades haya entre IF y la unidad que ejecute el salto
(modificaci√≥n PC).
La consecuencia de este riesgo de control es que cuando se actualice PC habr√° que
eliminar del cauce (vaciamiento) todas las instrucciones que se hayan le√≠do sin tener
¬© Universidad Internacional de La Rioja (UNIR)

en cuenta el salto (su n√∫mero depender√° de la profundidad del cauce). Esta p√©rdida
supondr√° una reducci√≥n del rendimiento de la cadena de ejecuci√≥n. La p√©rdida
obtenida ser√° menor cuanto menos tiempo tarde en actualizarse PC al valor que
deber√≠a tener tras la lectura de la instrucci√≥n.

Estructura de Computadores
Tema 5. Ideas clave

13

El problema de las rupturas de secuencia se complica si estas no se producen con
certeza, es decir, si son condicionales. Cuando se trata de saltos condicionales no solo
hay que tener en cuenta la actualizaci√≥n de PC, sino que esta puede ocurrir o no en
funci√≥n de la comprobaci√≥n de la condici√≥n, que depender√° de alguna instrucci√≥n
ejecutada previamente. Estas instrucciones combinan el efecto de un riesgo de
control (ruptura de secuencia) con un riesgo de dependencia (evaluaci√≥n de la
condici√≥n).

Ortega, Anguita y Prieto (2005) presentan una situaci√≥n sencilla de este problema,
a√±adiendo al procesador b√°sico, que se toma como ejemplo, una instrucci√≥n de salto
condicional del tipo ¬´bcnd Ra¬ª, ante los conflictos que provoca este tipo de
instrucci√≥n, se proponen dos t√©cnicas que se deben conocer:

ÔÇÑ Inserci√≥n de instrucciones NOP.
ÔÇÑ Salto retardado.

Son dos de las posibles t√©cnicas que se pueden plantear para resolver riesgos de este
tipo, en cualquier caso, las soluciones planteadas para este tipo de conflictos, y para
cualquiera, depender√°n de la arquitectura concreta sobre la que se pretenda aplicar,
aunque se mantenga la filosof√≠a de la soluci√≥n.

Implementaci√≥n de instrucciones de acceso a memoria
Los conflictos asociados a instrucciones de acceso a memoria permiten ilustrar los

¬© Universidad Internacional de La Rioja (UNIR)

llamados riesgos estructurales.

En este caso, Ortega, Anguita y Prieto (2005) emplean como ejemplo la incorporaci√≥n
de instrucciones de transferencia de informaci√≥n entre registros y memoria.
Instrucciones de tipo carga (load), transferencia de memoria a registro, y
almacenamiento (store), transferencia de registro a memoria. A partir de los

Estructura de Computadores
Tema 5. Ideas clave

14

problemas asociados a los accesos a memoria, se observa la necesidad de incluir dos
elementos nuevos:

ÔÇÑ La unidad de gesti√≥n de memoria (MMU, Memory Management Unit), incluida

en la arquitectura del procesador, que ser√° la encargada del c√°lculo de la direcci√≥n
f√≠sica de memoria (memoria virtual, direccionamientos relativos).
ÔÇÑ Una nueva etapa al cauce, que en el ejemplo se designa como MEM, para asumir

el coste en tiempo del acceso (gesti√≥n del acceso, disponibilidad de la
informaci√≥n, estados de espera).

En este apartado se observa adem√°s de la posibilidad de que existan riesgos RAW
que se involucren a operandos en memoria (retardo de uso de carga).

Espacio de dise√±o de los procesadores segmentados
Ortega, Anguita y Prieto (2005) presentan los aspectos que definen el espacio de

¬© Universidad Internacional de La Rioja (UNIR)

dise√±o de los procesadores segmentados:

Estructura de Computadores
Tema 5. Ideas clave

15

Aspectos que definen el espacio de dise√±o de los procesadores
segmentados

Seg√∫n la organizaci√≥n
del cauce

N√∫mero de etapas
Subtarea que
implementa cada etapa
Distribuci√≥n de la
secuencia de etapas

Seg√∫n las alternativas de
resoluci√≥n de dependencias
Est√°tica (Compilador)
Din√°mica (elementos
HW en ejecuci√≥n)
Combinada

‚Ä¢Cauce √∫nico
‚Ä¢Cauces dobles
‚Ä¢Cauces m√∫ltiples
Uso de atajos
Temporizaci√≥n del cauce
‚Ä¢S√≠ncrona
‚Ä¢As√≠ncrona
Figura 5. Aspectos que definen el espacio de dise√±o de los procesadores segmentados.

5.5. Optimizaci√≥n de causes funcionales
En este apartado se presentan los conceptos de cauce lineal y no lineal y se desarrolla
un sistema de dise√±o de unidad de control para optimizar un cauce no lineal (Ortega

¬© Universidad Internacional de La Rioja (UNIR)

et al., 2005).
ÔÇÑ Cauce Lineal: cada etapa est√° conectada solo con una etapa anterior y otra

posterior, y las entradas a procesar (instrucciones, operandos) se pueden
introducir en el cauce al ritmo de una cada ciclo de reloj.

Estructura de Computadores
Tema 5. Ideas clave

16

ÔÇÑ Cauces no lineales:

‚Ä¢ Hay etapas que necesitan varios ciclos de reloj.
‚Ä¢ Algunas etapas se vuelven a reutilizar por una misma operaci√≥n.
‚Ä¢ Una misma operaci√≥n (instrucci√≥n) puede utilizar m√°s de una etapa al mismo

tiempo.
‚Ä¢ El orden en que se visitan las etapas (y las etapas que se visitan) puede cambiar

de una operaci√≥n a otra (cauces multifuncionales).
‚Ä¢ Pueden existir dependencias entre las operaciones que se introducen en el

cauce, de forma que el orden en que una operaci√≥n visite las etapas cambie
din√°micamente (cauces din√°micos multifuncionales).
Adem√°s, la productividad de un cauce depende de que:

ÔÇÑ Que exista una fuente continua de operaciones (instrucciones) a realizar.
ÔÇÑ Que exista un procedimiento eficaz de planificaci√≥n del cauce.

En este punto se presentan adem√°s conceptos como la tabla de reservas, la latencia
prohibida, los ciclos avariciosos y el vector o matriz de colisiones.

5.6. Interrupciones en un procesador segmentado
Las interrupciones son dif√≠ciles de manejar en un procesador segmentado dado que
el solapamiento entre instrucciones hace m√°s dif√≠cil determinar el momento en que

¬© Universidad Internacional de La Rioja (UNIR)

una instrucci√≥n puede cambiar de forma segura el estado de la m√°quina.
La tabla 1 expone una clasificaci√≥n de los diferentes tipos de interrupci√≥n. Por otro
lado conviene tener en cuenta los siguientes conceptos relacionados con
interrupciones:
ÔÇÑ Excepciones S√≠ncronas/As√≠ncronas: Si el evento se produce en el mismo lugar

cada vez que se ejecuta el programa es s√≠ncrono. Los eventos as√≠ncronos se
Estructura de Computadores
Tema 5. Ideas clave

17

originan en los dispositivos externos al procesador y la memoria. Los eventos
as√≠ncronos son m√°s f√°ciles de manejar puesto que se pueden atender despu√©s de
que se complete la instrucci√≥n en curso.

ÔÇÑ Solicitadas por el usuario o sobrevenidas: Si las solicita el usuario no son

realmente excepciones puesto que son predecibles (se tratan como excepciones
porque utilizan el mismo mecanismo para almacenar y restaurar el estado). Las
sobrevenidas se deben a un evento que no controla el programa.
ÔÇÑ Enmascarables

o no enmascarables dentro de una instrucci√≥n o entre

instrucciones: Seg√∫n el evento impide que se termine la ejecuci√≥n de la
instrucci√≥n porque ocurre en mitad de la misma (son siempre excepciones
s√≠ncronas y son dif√≠ciles de procesar porque la instrucci√≥n debe pararse y empezar
de nuevo) o bien ocurren entre instrucciones.

ÔÇÑ Excepciones

para terminar o con continuaci√≥n (¬´terminate/resume¬ª) que

terminan el programa (catastr√≥ficas) o que permiten continuar el programa tras
ser procesadas (no catastr√≥ficas).
Indican una condici√≥n de error
y dan paso a una rutina de
recuperaci√≥n

Interrupciones cr√≠ticas
para comunicarse con el
S.O.
Memoria virtual

Fuente interna a la
CPU
Fuente externa

instrucciones no
Excepciones (A)

implementadas (B)

Fallo hardware (C)

Temporizaci√≥n E/S (D)

¬© Universidad Internacional de La Rioja (UNIR)

Tabla 1. Clasificaci√≥n de los distintos tipos de interrupci√≥n. Fuente: Ortega et al., 2005.

Seg√∫n se atiendan las interrupciones respetando o no el orden de ejecuci√≥n de las
instrucciones, se habla de interrupciones precisas o imprecisas.

Estructura de Computadores
Tema 5. Ideas clave

18

Interrupciones precisas
Permiten garantizar que despu√©s de una interrupci√≥n no catastr√≥fica, el proceso
interrumpido contin√∫e correctamente.

El estado de la m√°quina en el momento de la interrupci√≥n es id√©ntico al que existir√≠a
si la ejecuci√≥n fuese secuencial. Ese estado se llama estado preciso y cumple las
siguientes condiciones:
ÔÇÑ Todas las instrucciones que se emitieron antes de la instrucci√≥n indicada por el PC

almacenado (para continuar el proceso interrumpido) se han completado.
ÔÇÑ Las instrucciones posteriores al valor indicado por el PC almacenado no se

ejecutan y no han cambiado el estado del procesador.
ÔÇÑ Si la interrupci√≥n fue ocasionada por una instrucci√≥n, el contador de programa

apunta a esa instrucci√≥n, que puede ejecutarse completamente o no.

5.7. Referencias bibliogr√°ficas
Ortega, J., Anguita, M. y Prieto, A. (2005). Arquitectura de computadores. Madrid:

¬© Universidad Internacional de La Rioja (UNIR)

Thomson.

Estructura de Computadores
Tema 5. Ideas clave

19

A fondo
Procesadores ARM

Ortega, J., Anguita, M. y Prieto, A. (2005). Arquitectura de computadores. Madrid:
Thomson.
La descripci√≥n de la arquitectura ARM realizada en las p√°ginas 92 a 97 como
aplicaci√≥n pr√°ctica de la segmentaci√≥n de cauce.

Otra visi√≥n de los procesadores escalares

Para tener otra visi√≥n sobre la implementaci√≥n de la segmentaci√≥n de cauce en un
procesador, conviene revisar el tema 12 (p√°ginas 437 a 464) del libro Organizaci√≥n y
Arquitectura de Computadores, de William Stallings (Pearson, 2006). Si adem√°s se
busca tener una idea clara de las caracter√≠sticas de las arquitecturas CISC y RISC en
relaci√≥n con la segmentaci√≥n, tambi√©n se puede leer el tema 13 del mismo libro.

Accede a la p√°gina desde el aula virtual o a trav√©s de la siguiente direcci√≥n web:
https://pearson.es/espa%C3%B1a/TiendaOnline/organizaci%C3%B3n-yarquitectura-de-computadores

Segmentaci√≥n (Pipelining)

¬© Universidad Internacional de La Rioja (UNIR)

Hennessy, J. & Patterson, D. (2002). Arquitectura de computadores. Un enfoque
cuantitativo. Madrid: McGraw-Hill.

En el cap√≠tulo 6 (pp. 269 a 352). puedes encontrar el desarrollo de un procesador
did√°ctico cl√°sico para la segmentaci√≥n de cauce como el DLX, simplificaci√≥n del MIPS,
dise√±o que llevaron a cabo los autores en los a√±os 80.

Estructura de Computadores
Tema 5. A fondo

20

Assemblers, Linkers, and the SPIM Simulator

Larus, J.R. (1993). Assemblers, Linkers, and the SPIM Simulator. Recuperado de
http://pages.cs.wisc.edu/~larus/HP_AppA.pdf

Para conocer el ensamblador del procesador con segmentaci√≥n de cauce MIPS, se
puede revisar el ap√©ndice A.
PCI Express

Dubey, P. K. y Flynn, M. J. (1991, octubre). Branch Strategies: Modeling and Optimization.
IEEE

Transactions

on

Computers,

40(10).

Recuperado

de

http://i.stanford.edu/pub/cstr/reports/csl/tr/90/411/CSL-TR-90-411.pdf

Para profundizar en las t√©cnicas de reducci√≥n del efecto de los saltos en cadenas

¬© Universidad Internacional de La Rioja (UNIR)

segmentadas se puede revisar este art√≠culo.

Estructura de Computadores
Tema 5. A fondo

21

Actividades
Laboratorio #1: Simulaci√≥n y optimizaci√≥n de un
programa en un procesador escalar segmentado
Preparaci√≥n para el laboratorio

Antes de acudir al laboratorio deber√°s haber instalado en tu m√°quina el simulador
WinDLXV. Tambi√©n tendr√°s que haber le√≠do el manual correspondiente. Si no lo has
hecho previamente, descarga la herramienta y consulta los manuales de la misma en
el apartado Recursos Externos.

Descripci√≥n del laboratorio
En esta pr√°ctica vamos a trabajar la ejecuci√≥n segmentada de un programa para el
procesador DLX, bas√°ndonos en los resultados obtenidos en su simulaci√≥n,
intentaremos optimizarlo aplicando las t√©cnicas de desenrollado de bucles y de
reordenaci√≥n del c√≥digo comentadas en clase.
Entrega del laboratorio
Una vez finalizado el laboratorio deber√°s entregar un escrito en el que aparezcan los

¬© Universidad Internacional de La Rioja (UNIR)

siguientes puntos:

ÔÇÑ El resultado de la simulaci√≥n de la pr√°ctica propuesta incluyendo la imagen del

cronograma de ejecuci√≥n y de la pantalla de estad√≠sticas del simulador, indicando
d√≥nde se producen los parones en la ejecuci√≥n debidos a los conflictos que surjan.
ÔÇÑ El c√≥digo mejorado con los criterios propuestos en la pr√°ctica.
ÔÇÑ Repetir la simulaci√≥n del apartado 1 para el c√≥digo mejorado confirmando con ello

que se obtiene una ejecuci√≥n m√°s r√°pida.
Estructura de Computadores
Tema 5. Actividades

22

Test
1. La segmentaci√≥n de cauce‚Ä¶
A. Es una t√©cnica que se basa en agrupar varias unidades aritm√©ticas en el
procesador de modo que se puedan ejecutar un determinado n√∫mero de
operaciones simult√°neamente.
B. Consiste en dividir la ejecuci√≥n de instrucciones en fases y dise√±ar
procesadores formados por distintas etapas de modo que cada una de ellas
pueda desarrollar una fase de forma independiente.
C. Es una t√©cnica que se aplica en la configuraci√≥n de la jerarqu√≠a de memoria.
D. Las tres respuestas anteriores son correctas.

2. En un procesador segmentado‚Ä¶
A. Se pueden ejecutar varias instrucciones al mismo tiempo en diferentes fases
de ejecuci√≥n.
B. El procesador se divide en varios procesadores m√°s reducidos pero de
funcionalidad similar.
C. La longitud de la cadena depende del tama√±o de los operandos que maneje
el procesador.
D. Ninguna de las tres respuestas anteriores es correcta.

3. El TLI de un procesador segmentado‚Ä¶
A. Representa el tiempo que tardan en ejecutarse n instrucciones similares.
B. Indica la velocidad de ejecuci√≥n del cauce.

¬© Universidad Internacional de La Rioja (UNIR)

C. Representa el tiempo de ejecuci√≥n de una instrucci√≥n aislada o de la primera
instrucci√≥n de una aplicaci√≥n.
D. Las tres respuestas anteriores son correctas.

Estructura de Computadores
Tema 5. Test

23

4. La t√©cnica de segmentaci√≥n de cauce se implement√≥ por primera vez‚Ä¶
A. Para acelerar los accesos a memoria.
B. Para ejecutar mayor n√∫mero de instrucciones por unidad de tiempo.
C. Para aumentar el tama√±o de los operandos.
D. Para acelerar las operaciones en coma flotante.

5. Un procesador no segmentado tarda en ejecutar una instrucci√≥n un tiempo T, si
su unidad de ejecuci√≥n se divide en varias etapas cuyo tiempo de proceso es t y se
ejecutan n instrucciones‚Ä¶
A. La m√°xima ganancia que se obtendr√≠a en el segundo caso respecto al primero
ser√≠a T√ót.
B. La m√°xima ganancia que se obtendr√≠a en el segundo caso respecto al primero
ser√≠a T/n.
C. La m√°xima ganancia que se obtendr√≠a en el segundo caso respecto al primero
ser√≠a T/t.
D. La m√°xima ganancia que se obtendr√≠a en el segundo caso respecto al primero
ser√≠a t√ón.

6. Un procesador no segmentado tarda en ejecutar una instrucci√≥n un tiempo T, si
su unidad de ejecuci√≥n se divide en varias etapas cuyo tiempo de proceso es t y se
ejecutan n instrucciones, ‚Ä¶
A. ‚Ä¶ si T<TLI, la eficiencia m√°xima obtenible puede ser mayor que 1.
B. ‚Ä¶ si T<TLI, la eficiencia m√°xima obtenible ser√° menor que 1.
C. ‚Ä¶ si T<TLI, la eficiencia m√°xima obtenible ser√° 1.

¬© Universidad Internacional de La Rioja (UNIR)

D. Ninguna de las respuestas anteriores es cierta.

7. Respecto a los riesgos o conflictos en segmentaci√≥n de cauce, se puede decir:
A. Que pueden ser de datos, de control y estructurales.
B. Que nunca se pueden dar si el n√∫mero de etapas es par.
C. Que los conflictos de datos solo existen en procesadores superescalares.
D. Las tres respuestas anteriores son correctas.
Estructura de Computadores
Tema 5. Test

24

8. ¬øEn qu√© consiste la t√©cnica del salto retardado?
A. En que se retras√≥ el salto tanto como sea posible.
B. En que siempre se ejecute la instrucci√≥n que sigue al salto.
C. En que el salto se pueda realizar hacia delante y hacia atr√°s respecto a la
posici√≥n actual.
D. En que el salto a realizar se sit√∫e al final del programa.

9. Respecto a la resoluci√≥n de dependencias de la segmentaci√≥n de cauce:
A. Se dice que es est√°tica si depende de la optimizaci√≥n del hardware del
procesador.
B. Se dice que es din√°mica si cambia su comportamiento seg√∫n cambie la
instrucci√≥n.
C. Se dice que es din√°mica si depende del √∫ltimo resultado obtenido en la ALU.
D. Se dice que es est√°tica si el compilador ordena las instrucciones de forma
adecuada para evitar problemas derivados de las dependencias.

10. En un procesador segmentado:
A. El cauce es lineal si cada etapa conectada solo tiene una etapa anterior y otra
posterior, y las instrucciones se pueden introducir en el cauce al ritmo de una
cada ciclo de reloj.
B. El cauce es lineal si admite que una misma instrucci√≥n reutilice la misma
etapa varia veces.
C. Una interrupci√≥n es precisa si tras atenderla se vuelve a ejecutar siempre la
instrucci√≥n que se estaba procesando cuando apareci√≥.

¬© Universidad Internacional de La Rioja (UNIR)

D. Ninguna de las afirmaciones anteriores es correcta.

Estructura de Computadores
Tema 5. Test

25

